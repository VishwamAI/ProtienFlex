============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/kasinadhsarma/Pictures/ProtienFlex
configfile: pyproject.toml
plugins: cov-6.0.0, anyio-4.7.0
collected 136 items

tests/analysis/test_multimodal_integration.py ......                     [  4%]
tests/generative/test_concept_bottleneck.py ......                       [  8%]
tests/generative/test_graph_attention.py .....                           [ 12%]
tests/generative/test_protein_generator.py .....                         [ 16%]
tests/generative/test_structure_generator.py .F...F                      [ 20%]
tests/integration/test_optimization_pipeline.py EEEEEEEEEEE              [ 28%]
tests/integration/test_performance_benchmarks.py EEEEEEE                 [ 33%]
tests/integration/test_protein_validation.py EEEEEEEE                    [ 39%]
tests/optimizers/test_adaptive_processor.py EEEEEEEEEEEEEFFFE            [ 52%]
tests/optimizers/test_memory_manager.py .............                    [ 61%]
tests/optimizers/test_performance_monitor.py ..............F             [ 72%]
tests/sampling/test_attention_based_sampler.py ....                      [ 75%]
tests/sampling/test_confidence_guided_sampler.py ......                  [ 80%]
tests/sampling/test_energy_based_sampler.py ........                     [ 86%]
tests/sampling/test_graph_based_sampler.py .......                       [ 91%]
tests/test_dynamics.py ......                                            [ 95%]
tests/test_mutation_analysis.py ......
WARNING: Failed to generate report: No data to report.

                                                                         [100%]

==================================== ERRORS ====================================
____________ ERROR at setup of test_complete_optimization_pipeline _____________

temp_log_dir = '/tmp/tmp5wjq4uss'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b99a6770>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_pipeline_adaptation __________________

temp_log_dir = '/tmp/tmps3qe1lsi'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba477940>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______________ ERROR at setup of test_pipeline_memory_efficiency _______________

temp_log_dir = '/tmp/tmptqj2x1jb'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4a7af0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________ ERROR at setup of test_pipeline_performance_tracking _____________

temp_log_dir = '/tmp/tmpj4lp8vqz'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9f03610>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________________ ERROR at setup of test_pipeline_error_handling ________________

temp_log_dir = '/tmp/tmpyviatbjg'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98649d0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________ ERROR at setup of test_pipeline_different_batch_sizes[8] ___________

temp_log_dir = '/tmp/tmpbnih581v'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b97b8190>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________ ERROR at setup of test_pipeline_different_batch_sizes[16] ___________

temp_log_dir = '/tmp/tmpjvrlwane'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98d0cd0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________ ERROR at setup of test_pipeline_different_batch_sizes[32] ___________

temp_log_dir = '/tmp/tmpb57rkwni'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9fc83a0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[10] ________

temp_log_dir = '/tmp/tmpisl0ertk'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4a66b0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[20] ________

temp_log_dir = '/tmp/tmpzx1ynxti'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98d1510>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[30] ________

temp_log_dir = '/tmp/tmp5gf0rzoj'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b985f7c0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestPerformanceBenchmarks.test_latency_benchmarks ______

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b97b96c0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
____ ERROR at setup of TestPerformanceBenchmarks.test_throughput_benchmarks ____

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98d1690>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_ ERROR at setup of TestPerformanceBenchmarks.test_memory_efficiency_benchmarks _

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b985fb80>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestPerformanceBenchmarks.test_accuracy_benchmarks _____

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b97b8250>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O1] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9860a60>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O2] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4c40a0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O3] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9fcb9d0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of TestProteinValidation.test_sequence_accuracy ________

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9f03f40>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______ ERROR at setup of TestProteinValidation.test_structure_prediction _______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b97bbbb0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of TestProteinValidation.test_fold_recognition _________

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9fc9e70>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_binding_site_prediction _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b99a61a0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[50] ______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98d0ac0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[100] _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9fca5c0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[200] _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9865ff0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_result_reproducibility ______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4c5fc0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________ ERROR at setup of test_adaptive_processor_initialization ___________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba30c850>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_hardware_detection ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9866590>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_optimize_for_hardware _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b985ca60>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_profile_execution ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4f6920>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_adapt_processing ____________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba30f7c0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_mixed_precision[fp32] _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4a4910>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_mixed_precision[fp16] _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b9f02500>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______________ ERROR at setup of test_memory_access_optimization _______________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b98666b0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_operation_fusion ____________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4c6d70>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_performance_metrics __________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba30f520>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[1] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba3e0640>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[2] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4ded70>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[4] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4b97b8eb0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_layer_optimization ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4a5060>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
=================================== FAILURES ===================================
________________ TestStructureAwareGenerator.test_gradient_flow ________________

self = <tests.generative.test_structure_generator.TestStructureAwareGenerator testMethod=test_gradient_flow>

    def test_gradient_flow(self):
        """Test gradient flow through the generator"""
        input_ids = torch.randint(
            0, 22, (self.batch_size, self.seq_length),
            requires_grad=False
        )
    
        # Forward pass
        outputs = self.generator(input_ids)
        loss = outputs["logits"].sum()
        loss.backward()
    
        # Check gradients
        for param in self.generator.parameters():
            if param.requires_grad:
>               self.assertIsNotNone(param.grad)
E               AssertionError: unexpectedly None

tests/generative/test_structure_generator.py:135: AssertionError
_________ TestStructureAwareGenerator.test_structure_guided_generation _________

self = <tests.generative.test_structure_generator.TestStructureAwareGenerator testMethod=test_structure_guided_generation>

    def test_structure_guided_generation(self):
        """Test generation with structural guidance"""
        start_tokens = torch.randint(0, 22, (self.batch_size, 2))
        max_length = 10
        distance_matrix = torch.randn(
            self.batch_size, max_length, max_length
        )
        angle_matrix = torch.randn(
            self.batch_size, max_length, max_length
        )
    
>       generated = self.generator.generate(
            start_tokens=start_tokens,
            max_length=max_length,
            temperature=0.8,
            distance_matrix=distance_matrix,
            angle_matrix=angle_matrix
        )

tests/generative/test_structure_generator.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/generative/structure_generator.py:157: in generate
    outputs = self.forward(
models/generative/structure_generator.py:106: in forward
    layer_output, attn_weights = attention_layer(
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GraphAttentionLayer(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, ...(output_dropout): Dropout(p=0.1, inplace=False)
  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
hidden_states = tensor([[[-0.2133, -1.5019,  0.2690,  ...,  0.5587, -0.1340,  0.0178],
         [ 1.5458,  0.0522, -1.1695,  ..., -1.4...4574,  0.0000],
         [ 2.0462, -0.0829, -0.1333,  ..., -0.0000, -1.5385, -1.1402]]],
       grad_fn=<MulBackward0>)
distance_matrix = tensor([[[-0.3261, -0.9820,  1.0624, -1.2498,  0.1626, -0.1744,  0.6472,
           0.3154, -0.0772, -0.2846],
       ...3828],
         [ 0.4845, -2.5501,  1.0480, -0.4265,  1.1760, -1.1217, -0.8001,
           0.3470, -2.9748,  0.3945]]])
angle_matrix = tensor([[[-0.5184, -1.4005, -0.7356, -0.1590,  0.4107,  0.4992, -1.2366,
          -2.0018, -0.1628, -0.5798],
       ...5004],
         [-0.6421,  0.7192, -0.9510,  1.5766, -1.2018, -0.5078, -0.5575,
           0.6103,  0.3236, -0.6996]]])
attention_mask = None

    def forward(
        self,
        hidden_states: torch.Tensor,
        distance_matrix: Optional[torch.Tensor] = None,
        angle_matrix: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass with structure awareness
    
        Args:
            hidden_states: Input tensor [batch_size, seq_length, hidden_size]
            distance_matrix: Pairwise distances [batch_size, seq_length, seq_length]
            angle_matrix: Pairwise angles [batch_size, seq_length, seq_length]
            attention_mask: Attention mask [batch_size, seq_length]
    
        Returns:
            output: Transformed hidden states
            attention_probs: Attention probabilities
        """
        # Linear transformations
        query_layer = self.transpose_for_scores(self.query(hidden_states))
        key_layer = self.transpose_for_scores(self.key(hidden_states))
        value_layer = self.transpose_for_scores(self.value(hidden_states))
    
        # Compute base attention scores
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
    
        # Add structure awareness if available
        if distance_matrix is not None:
            # Get distance embeddings [batch_size, seq_length, seq_length, 1]
            distance_embeddings = self.distance_embedding(distance_matrix.unsqueeze(-1))
    
            # Project embeddings to attention head size
            batch_size, seq_len_i, seq_len_j, embed_dim = distance_embeddings.size()
    
            # Reshape to match attention scores: [batch_size, num_heads, seq_len, seq_len]
            distance_scores = distance_embeddings.squeeze(-1)  # Remove last dimension
            distance_scores = distance_scores.unsqueeze(1)     # Add head dimension
            distance_scores = distance_scores.expand(-1, self.num_attention_heads, -1, -1)
    
            # Add to attention scores
>           attention_scores = attention_scores + distance_scores
E           RuntimeError: The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 3

models/generative/graph_attention.py:96: RuntimeError
_____________________ test_different_latency_targets[0.1] ______________________

target_latency = 0.1

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba30d540>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________________ test_different_latency_targets[0.5] ______________________

target_latency = 0.5

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4f47f0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________________ test_different_latency_targets[1.0] ______________________

target_latency = 1.0

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x7ea4ba4df670>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
____________________________ test_log_file_creation ____________________________

performance_monitor = <models.optimizers.performance_monitor.PerformanceMonitor object at 0x7ea4b9860820>
temp_log_dir = '/tmp/tmpi8u86p6m'

    def test_log_file_creation(performance_monitor, temp_log_dir):
        """Test log file creation and writing."""
        log_file = Path(temp_log_dir) / "performance.log"
        assert log_file.exists()
    
        # Generate some logs
        performance_monitor._log_metrics("test", {"value": 1.0})
    
        # Check log file content
>       assert log_file.stat().st_size > 0
E       AssertionError: assert 0 > 0
E        +  where 0 = os.stat_result(st_mode=33204, st_ino=5511093, st_dev=66306, st_nlink=1, st_uid=1000, st_gid=1000, st_size=0, st_atime=1734524627, st_mtime=1734524627, st_ctime=1734524627).st_size
E        +    where os.stat_result(st_mode=33204, st_ino=5511093, st_dev=66306, st_nlink=1, st_uid=1000, st_gid=1000, st_size=0, st_atime=1734524627, st_mtime=1734524627, st_ctime=1734524627) = stat()
E        +      where stat = PosixPath('/tmp/tmpi8u86p6m/performance.log').stat

tests/optimizers/test_performance_monitor.py:204: AssertionError
=============================== warnings summary ===============================
../../.local/lib/python3.10/site-packages/Bio/SubsMat/__init__.py:126
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.
    warnings.warn(

tests/integration/test_performance_benchmarks.py:73
  /home/kasinadhsarma/Pictures/ProtienFlex/tests/integration/test_performance_benchmarks.py:73: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.benchmark

tests/integration/test_protein_validation.py:88
  /home/kasinadhsarma/Pictures/ProtienFlex/tests/integration/test_protein_validation.py:88: PytestUnknownMarkWarning: Unknown pytest.mark.validation - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.validation

tests/analysis/test_multimodal_integration.py::test_sequence_analysis
tests/analysis/test_multimodal_integration.py::test_structure_prediction
tests/analysis/test_multimodal_integration.py::test_function_prediction
tests/analysis/test_multimodal_integration.py::test_multimodal_integration
tests/analysis/test_multimodal_integration.py::test_cross_modal_attention
tests/analysis/test_multimodal_integration.py::test_confidence_estimation
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
    warnings.warn(

tests/optimizers/test_memory_manager.py::test_checkpoint_sequential
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
    warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform linux, python 3.10.12-final-0 ----------

=========================== short test summary info ============================
ERROR tests/integration/test_optimization_pipeline.py::test_complete_optimization_pipeline
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_adaptation
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_memory_efficiency
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_performance_tracking
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_error_handling
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[8]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[16]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[32]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[10]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[20]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[30]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_latency_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_throughput_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_memory_efficiency_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_accuracy_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O1]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O2]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O3]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_sequence_accuracy
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_structure_prediction
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_fold_recognition
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_binding_site_prediction
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[50]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[100]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[200]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_result_reproducibility
ERROR tests/optimizers/test_adaptive_processor.py::test_adaptive_processor_initialization
ERROR tests/optimizers/test_adaptive_processor.py::test_hardware_detection - ...
ERROR tests/optimizers/test_adaptive_processor.py::test_optimize_for_hardware
ERROR tests/optimizers/test_adaptive_processor.py::test_profile_execution - A...
ERROR tests/optimizers/test_adaptive_processor.py::test_adapt_processing - At...
ERROR tests/optimizers/test_adaptive_processor.py::test_mixed_precision[fp32]
ERROR tests/optimizers/test_adaptive_processor.py::test_mixed_precision[fp16]
ERROR tests/optimizers/test_adaptive_processor.py::test_memory_access_optimization
ERROR tests/optimizers/test_adaptive_processor.py::test_operation_fusion - At...
ERROR tests/optimizers/test_adaptive_processor.py::test_performance_metrics
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[1]
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[2]
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[4]
ERROR tests/optimizers/test_adaptive_processor.py::test_layer_optimization - ...
FAILED tests/generative/test_structure_generator.py::TestStructureAwareGenerator::test_gradient_flow
FAILED tests/generative/test_structure_generator.py::TestStructureAwareGenerator::test_structure_guided_generation
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[0.1]
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[0.5]
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[1.0]
FAILED tests/optimizers/test_performance_monitor.py::test_log_file_creation
======= 6 failed, 90 passed, 10 warnings, 40 errors in 85.14s (0:01:25) ========
