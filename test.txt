============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/kasinadhsarma/Pictures/ProtienFlex
configfile: pyproject.toml
testpaths: tests
plugins: cov-6.0.0, anyio-4.7.0
collected 136 items

tests/analysis/test_multimodal_integration.py ......                     [  4%]
tests/generative/test_concept_bottleneck.py ......                       [  8%]
tests/generative/test_graph_attention.py F...F                           [ 12%]
tests/generative/test_protein_generator.py FFFFF                         [ 16%]
tests/generative/test_structure_generator.py .F..FF                      [ 20%]
tests/integration/test_optimization_pipeline.py EEEEEEEEEEE              [ 28%]
tests/integration/test_performance_benchmarks.py EEEEEEE                 [ 33%]
tests/integration/test_protein_validation.py EEEEEEEE                    [ 39%]
tests/optimizers/test_adaptive_processor.py EEEEEEEEEEEEEFFFE            [ 52%]
tests/optimizers/test_memory_manager.py .............                    [ 61%]
tests/optimizers/test_performance_monitor.py ..............F             [ 72%]
tests/sampling/test_attention_based_sampler.py ....                      [ 75%]
tests/sampling/test_confidence_guided_sampler.py ......                  [ 80%]
tests/sampling/test_energy_based_sampler.py ........                     [ 86%]
tests/sampling/test_graph_based_sampler.py .......                       [ 91%]
tests/test_dynamics.py ......                                            [ 95%]
tests/test_mutation_analysis.py ......
WARNING: Failed to generate report: No data to report.

                                                                         [100%]

==================================== ERRORS ====================================
____________ ERROR at setup of test_complete_optimization_pipeline _____________

temp_log_dir = '/tmp/tmpm_erbip4'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40197a30>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_pipeline_adaptation __________________

temp_log_dir = '/tmp/tmpp3x6xl0n'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40168370>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______________ ERROR at setup of test_pipeline_memory_efficiency _______________

temp_log_dir = '/tmp/tmphgzk0hqu'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401bfcd0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________ ERROR at setup of test_pipeline_performance_tracking _____________

temp_log_dir = '/tmp/tmphgudsp7s'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4054d900>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________________ ERROR at setup of test_pipeline_error_handling ________________

temp_log_dir = '/tmp/tmpxl0qkpxi'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40fecd90>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________ ERROR at setup of test_pipeline_different_batch_sizes[8] ___________

temp_log_dir = '/tmp/tmppbsvridw'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40002d10>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________ ERROR at setup of test_pipeline_different_batch_sizes[16] ___________

temp_log_dir = '/tmp/tmp9591njrd'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401ec250>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________ ERROR at setup of test_pipeline_different_batch_sizes[32] ___________

temp_log_dir = '/tmp/tmpc9w6epzk'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac41941c30>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[10] ________

temp_log_dir = '/tmp/tmpv2bbpni5'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401be8f0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[20] ________

temp_log_dir = '/tmp/tmp_clne0an'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40f65900>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of test_pipeline_different_sequence_lengths[30] ________

temp_log_dir = '/tmp/tmpwwf6x8gg'

    @pytest.fixture
    def optimization_components(temp_log_dir):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8,
                log_dir=temp_log_dir
            )
        }

tests/integration/test_optimization_pipeline.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac41943490>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestPerformanceBenchmarks.test_latency_benchmarks ______

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401be860>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
____ ERROR at setup of TestPerformanceBenchmarks.test_throughput_benchmarks ____

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40f657e0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_ ERROR at setup of TestPerformanceBenchmarks.test_memory_efficiency_benchmarks _

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40518eb0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestPerformanceBenchmarks.test_accuracy_benchmarks _____

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4021a050>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O1] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40169030>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O2] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401a4310>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___ ERROR at setup of TestPerformanceBenchmarks.test_optimization_levels[O3] ___

    @pytest.fixture
    def optimization_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            )
        }

tests/integration/test_performance_benchmarks.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4051ba60>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of TestProteinValidation.test_sequence_accuracy ________

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40003e20>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______ ERROR at setup of TestProteinValidation.test_structure_prediction _______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4016bc10>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
________ ERROR at setup of TestProteinValidation.test_fold_recognition _________

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40f651b0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_binding_site_prediction _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401a6e00>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[50] ______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401ee500>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[100] _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40195150>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_length_scalability[200] _____

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4021a770>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____ ERROR at setup of TestProteinValidation.test_result_reproducibility ______

    @pytest.fixture
    def validation_pipeline():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return {
            "memory_manager": MemoryManager(device=device),
>           "adaptive_processor": AdaptiveProcessor(device=device),
            "performance_monitor": PerformanceMonitor(
                target_latency=1.0,
                target_accuracy=0.95,
                target_memory_efficiency=0.8
            ),
            "structure_validator": ProteinStructureValidator()
        }

tests/integration/test_protein_validation.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac41942860>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________ ERROR at setup of test_adaptive_processor_initialization ___________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40fef850>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_hardware_detection ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4054e4a0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_optimize_for_hardware _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40f67580>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_profile_execution ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40000520>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_adapt_processing ____________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40218ac0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_mixed_precision[fp32] _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401948b0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_________________ ERROR at setup of test_mixed_precision[fp16] _________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4016a7d0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
______________ ERROR at setup of test_memory_access_optimization _______________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac41942740>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
___________________ ERROR at setup of test_operation_fusion ____________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40002680>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_performance_metrics __________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40194dc0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[1] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401a68f0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[2] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac41942170>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_______________ ERROR at setup of test_different_batch_sizes[4] ________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4021b730>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
__________________ ERROR at setup of test_layer_optimization ___________________

    @pytest.fixture
    def adaptive_processor():
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       return AdaptiveProcessor(device=device)

tests/optimizers/test_adaptive_processor.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4021b8b0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
=================================== FAILURES ===================================
_________________ TestGraphAttentionLayer.test_attention_mask __________________

self = <tests.generative.test_graph_attention.TestGraphAttentionLayer testMethod=test_attention_mask>

    def test_attention_mask(self):
        """Test attention masking"""
        hidden_states = torch.randn(
            self.batch_size, self.seq_length, self.hidden_size
        )
        attention_mask = torch.ones(
            self.batch_size, self.seq_length
        )
        attention_mask[:, 5:] = 0  # Mask out second half of sequence
    
>       output, attention_probs = self.layer(
            hidden_states,
            attention_mask=attention_mask
        )

tests/generative/test_graph_attention.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GraphAttentionLayer(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, ...(output_dropout): Dropout(p=0.1, inplace=False)
  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
hidden_states = tensor([[[ 0.3111, -0.0139, -0.6746,  ..., -0.1453, -0.5056, -1.8921],
         [ 1.9877, -2.6044, -1.0399,  ...,  0.3...34, -1.4033,  ...,  0.1391, -0.1381, -1.3689],
         [-0.0631, -1.0588,  0.5692,  ..., -0.7987, -1.9661,  0.4535]]])
distance_matrix = None, angle_matrix = None
attention_mask = tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],
        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])

    def forward(
        self,
        hidden_states: torch.Tensor,
        distance_matrix: Optional[torch.Tensor] = None,
        angle_matrix: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass with structure awareness
    
        Args:
            hidden_states: Input tensor [batch_size, seq_length, hidden_size]
            distance_matrix: Pairwise distances [batch_size, seq_length, seq_length]
            angle_matrix: Pairwise angles [batch_size, seq_length, seq_length]
            attention_mask: Attention mask [batch_size, seq_length]
    
        Returns:
            output: Transformed hidden states
            attention_probs: Attention probabilities
        """
        # Linear transformations
        query_layer = self.transpose_for_scores(self.query(hidden_states))
        key_layer = self.transpose_for_scores(self.key(hidden_states))
        value_layer = self.transpose_for_scores(self.value(hidden_states))
    
        # Compute base attention scores
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
    
        # Add structure awareness if available
        if distance_matrix is not None:
            distance_embeddings = self.distance_embedding(distance_matrix.unsqueeze(-1))
            attention_scores = attention_scores + torch.matmul(
                query_layer, distance_embeddings.transpose(-1, -2)
            )
    
        if angle_matrix is not None:
            angle_embeddings = self.angle_embedding(angle_matrix.unsqueeze(-1))
            attention_scores = attention_scores + torch.matmul(
                query_layer, angle_embeddings.transpose(-1, -2)
            )
    
        # Apply attention mask if provided
        if attention_mask is not None:
>           attention_scores = attention_scores + (1.0 - attention_mask) * -10000.0
E           RuntimeError: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 2

models/generative/graph_attention.py:97: RuntimeError
____________ TestGraphAttentionLayer.test_structure_aware_attention ____________

self = <tests.generative.test_graph_attention.TestGraphAttentionLayer testMethod=test_structure_aware_attention>

    def test_structure_aware_attention(self):
        """Test forward pass with structural information"""
        hidden_states = torch.randn(
            self.batch_size, self.seq_length, self.hidden_size
        )
        distance_matrix = torch.randn(
            self.batch_size, self.seq_length, self.seq_length
        )
        angle_matrix = torch.randn(
            self.batch_size, self.seq_length, self.seq_length
        )
    
>       output, attention_probs = self.layer(
            hidden_states,
            distance_matrix=distance_matrix,
            angle_matrix=angle_matrix
        )

tests/generative/test_graph_attention.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GraphAttentionLayer(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, ...(output_dropout): Dropout(p=0.1, inplace=False)
  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
hidden_states = tensor([[[-1.4383,  0.5983,  0.8873,  ...,  0.9666, -0.9052,  0.7819],
         [-1.0167, -1.1629,  0.8792,  ...,  1.0...55,  0.7182,  ..., -0.5750,  2.4543,  0.1636],
         [ 0.5990, -1.3894, -0.2408,  ...,  0.9561,  1.3139,  0.5718]]])
distance_matrix = tensor([[[-1.8358,  0.9523,  1.7551,  1.2981, -0.0264, -0.7436,  0.2069,
           0.4788,  1.5433,  0.7471],
       ...3311],
         [ 0.8001,  1.3855,  1.3462, -1.5763,  1.2805,  0.9770, -0.2002,
          -1.7443, -0.5874, -1.9181]]])
angle_matrix = tensor([[[-0.1188, -0.9413, -0.0639,  0.4965,  0.3920, -0.9647, -0.2489,
          -1.5275, -1.0904,  0.2680],
       ...0327],
         [ 0.9884,  0.2325, -0.2962,  1.6318, -1.9254, -0.1742,  0.7571,
          -1.0639,  1.2278, -0.6918]]])
attention_mask = None

    def forward(
        self,
        hidden_states: torch.Tensor,
        distance_matrix: Optional[torch.Tensor] = None,
        angle_matrix: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass with structure awareness
    
        Args:
            hidden_states: Input tensor [batch_size, seq_length, hidden_size]
            distance_matrix: Pairwise distances [batch_size, seq_length, seq_length]
            angle_matrix: Pairwise angles [batch_size, seq_length, seq_length]
            attention_mask: Attention mask [batch_size, seq_length]
    
        Returns:
            output: Transformed hidden states
            attention_probs: Attention probabilities
        """
        # Linear transformations
        query_layer = self.transpose_for_scores(self.query(hidden_states))
        key_layer = self.transpose_for_scores(self.key(hidden_states))
        value_layer = self.transpose_for_scores(self.value(hidden_states))
    
        # Compute base attention scores
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
    
        # Add structure awareness if available
        if distance_matrix is not None:
            distance_embeddings = self.distance_embedding(distance_matrix.unsqueeze(-1))
>           attention_scores = attention_scores + torch.matmul(
                query_layer, distance_embeddings.transpose(-1, -2)
            )
E           RuntimeError: The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 1

models/generative/graph_attention.py:85: RuntimeError
_________________ TestProteinGenerator.test_concept_alignment __________________

self = <tests.generative.test_protein_generator.TestProteinGenerator testMethod=test_concept_alignment>

    def test_concept_alignment(self):
        """Test concept alignment evaluation"""
        current_concepts = {
            "structure": torch.rand(self.batch_size, self.seq_length, 16, device=self.device),
            "chemistry": torch.rand(self.batch_size, self.seq_length, 16, device=self.device),
            "function": torch.rand(self.batch_size, self.seq_length, 16, device=self.device),
            "interaction": torch.rand(self.batch_size, self.seq_length, 16, device=self.device)
        }
    
        target_concepts = {
            "structure": torch.tensor([0.8, 0.2, 0.1], device=self.device),
            "chemistry": torch.tensor([0.6, 0.4, 0.5], device=self.device)
        }
    
>       scores = self.model._evaluate_concept_alignment(current_concepts, target_concepts)

tests/generative/test_protein_generator.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = ProteinGenerativeModel(
  (embeddings): Embedding(25, 768, padding_idx=0)
  (position_embeddings): Embedding(512, 768)...tures=3072, out_features=3, bias=True)
  )
  (output_projection): Linear(in_features=768, out_features=25, bias=True)
)
current_concepts = {'chemistry': tensor([[[0.6760, 0.0921, 0.6320,  ..., 0.9045, 0.9870, 0.2197],
         [0.0109, 0.2958, 0.2653,  ...,...
         [3.5773e-01, 6.3153e-01, 9.7264e-01,  ..., 3.2043e-01,
          9.3671e-01, 8.8758e-01]]], device='cuda:0')}
target_concepts = {'chemistry': tensor([0.6000, 0.4000, 0.5000], device='cuda:0'), 'structure': tensor([0.8000, 0.2000, 0.1000], device='cuda:0')}

    def _evaluate_concept_alignment(
        self,
        current_concepts: Dict[str, torch.Tensor],
        target_concepts: Optional[Dict[str, float]] = None
    ) -> torch.Tensor:
        """Evaluate alignment between current and target concepts"""
        if target_concepts is None:
            return torch.zeros(
                current_concepts[list(current_concepts.keys())[0]].size(0),
                device=self.device
            )
    
        alignment_scores = []
        for concept_type, target_value in target_concepts.items():
            if concept_type in current_concepts:
                current_value = current_concepts[concept_type].to(self.device)
                target_tensor = torch.tensor(target_value, device=self.device)
                # Calculate similarity between current and target concept values
>               diff = torch.abs(current_value - target_tensor)
E               RuntimeError: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 2

models/generative/protein_generator.py:666: RuntimeError
____________________ TestProteinGenerator.test_forward_pass ____________________

self = <tests.generative.test_protein_generator.TestProteinGenerator testMethod=test_forward_pass>

    def test_forward_pass(self):
        """Test forward pass with concept bottleneck"""
>       outputs = self.model(
            input_ids=self.input_ids,
            output_attentions=True,
            output_hidden_states=True,
            return_concepts=True
        )

tests/generative/test_protein_generator.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
models/generative/protein_generator.py:374: in forward
    aa_indices = torch.tensor([[self.aa_to_idx[self.idx_to_aa[id.item()]]
models/generative/protein_generator.py:374: in <listcomp>
    aa_indices = torch.tensor([[self.aa_to_idx[self.idx_to_aa[id.item()]]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x79ac40247370>

>   aa_indices = torch.tensor([[self.aa_to_idx[self.idx_to_aa[id.item()]]
                              for id in seq] for seq in input_ids], device=device)
E   KeyError: 24

models/generative/protein_generator.py:374: KeyError
_______________ TestProteinGenerator.test_generate_with_concepts _______________

self = <tests.generative.test_protein_generator.TestProteinGenerator testMethod=test_generate_with_concepts>

    def test_generate_with_concepts(self):
        """Test protein generation with concept guidance"""
        prompt_text = "Generate a stable alpha-helical protein"
        target_concepts = {
            "structure": torch.tensor([0.8, 0.2, 0.1], device=self.device),  # Alpha helix preference
            "chemistry": torch.tensor([0.6, 0.4, 0.5], device=self.device),
            "function": torch.tensor([0.7, 0.3, 0.4], device=self.device),
            "interaction": torch.tensor([0.5, 0.5, 0.5], device=self.device)
        }
    
>       sequences = self.model.generate(
            prompt_text=prompt_text,
            max_length=32,
            num_return_sequences=2,
            temperature=0.8,
            concept_guidance=True,
            target_concepts=target_concepts
        )

tests/generative/test_protein_generator.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/generative/protein_generator.py:526: in generate
    encoded = self.tokenizer(prompt_text, return_tensors="pt").to(device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = ProteinGenerativeModel(
  (embeddings): Embedding(25, 768, padding_idx=0)
  (position_embeddings): Embedding(512, 768)...tures=3072, out_features=3, bias=True)
  )
  (output_projection): Linear(in_features=768, out_features=25, bias=True)
)
name = 'tokenizer'

    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
        if '_parameters' in self.__dict__:
            _parameters = self.__dict__['_parameters']
            if name in _parameters:
                return _parameters[name]
        if '_buffers' in self.__dict__:
            _buffers = self.__dict__['_buffers']
            if name in _buffers:
                return _buffers[name]
        if '_modules' in self.__dict__:
            modules = self.__dict__['_modules']
            if name in modules:
                return modules[name]
>       raise AttributeError("'{}' object has no attribute '{}'".format(
            type(self).__name__, name))
E       AttributeError: 'ProteinGenerativeModel' object has no attribute 'tokenizer'

../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1614: AttributeError
_______________ TestProteinGenerator.test_structural_validation ________________

self = <tests.generative.test_protein_generator.TestProteinGenerator testMethod=test_structural_validation>

    def test_structural_validation(self):
        """Test structural validation during generation"""
        angles = torch.randn(self.batch_size, self.seq_length, 3, device=self.device)
        scores = self.model._evaluate_structural_validity(angles)
    
        # Check score shape and range
>       self.assertEqual(scores.shape, (self.batch_size,))
E       AssertionError: torch.Size([4, 16]) != (4,)

tests/generative/test_protein_generator.py:88: AssertionError
_________________ TestProteinGenerator.test_template_guidance __________________

self = <tests.generative.test_protein_generator.TestProteinGenerator testMethod=test_template_guidance>

    def test_template_guidance(self):
        """Test template-guided generation"""
        template_sequence = "MLKFVAVVVL"
>       sequences = self.model.generate(
            prompt_text="Generate a protein similar to the template",
            max_length=32,
            num_return_sequences=2,
            template_sequence=template_sequence
        )

tests/generative/test_protein_generator.py:116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/generative/protein_generator.py:526: in generate
    encoded = self.tokenizer(prompt_text, return_tensors="pt").to(device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = ProteinGenerativeModel(
  (embeddings): Embedding(25, 768, padding_idx=0)
  (position_embeddings): Embedding(512, 768)...tures=3072, out_features=3, bias=True)
  )
  (output_projection): Linear(in_features=768, out_features=25, bias=True)
)
name = 'tokenizer'

    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
        if '_parameters' in self.__dict__:
            _parameters = self.__dict__['_parameters']
            if name in _parameters:
                return _parameters[name]
        if '_buffers' in self.__dict__:
            _buffers = self.__dict__['_buffers']
            if name in _buffers:
                return _buffers[name]
        if '_modules' in self.__dict__:
            modules = self.__dict__['_modules']
            if name in modules:
                return modules[name]
>       raise AttributeError("'{}' object has no attribute '{}'".format(
            type(self).__name__, name))
E       AttributeError: 'ProteinGenerativeModel' object has no attribute 'tokenizer'

../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1614: AttributeError
________________ TestStructureAwareGenerator.test_gradient_flow ________________

self = <tests.generative.test_structure_generator.TestStructureAwareGenerator testMethod=test_gradient_flow>

    def test_gradient_flow(self):
        """Test gradient flow through the generator"""
        input_ids = torch.randint(
            0, 22, (self.batch_size, self.seq_length),
            requires_grad=False
        )
    
        # Forward pass
        outputs = self.generator(input_ids)
        loss = outputs["logits"].sum()
        loss.backward()
    
        # Check gradients
        for param in self.generator.parameters():
            if param.requires_grad:
>               self.assertIsNotNone(param.grad)
E               AssertionError: unexpectedly None

tests/generative/test_structure_generator.py:135: AssertionError
_________ TestStructureAwareGenerator.test_structure_aware_generation __________

self = <tests.generative.test_structure_generator.TestStructureAwareGenerator testMethod=test_structure_aware_generation>

    def test_structure_aware_generation(self):
        """Test forward pass with structural information"""
        input_ids = torch.randint(0, 22, (self.batch_size, self.seq_length))
        distance_matrix = torch.randn(
            self.batch_size, self.seq_length, self.seq_length
        )
        angle_matrix = torch.randn(
            self.batch_size, self.seq_length, self.seq_length
        )
    
>       outputs = self.generator(
            input_ids,
            distance_matrix=distance_matrix,
            angle_matrix=angle_matrix
        )

tests/generative/test_structure_generator.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
models/generative/structure_generator.py:106: in forward
    layer_output, attn_weights = attention_layer(
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GraphAttentionLayer(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, ...(output_dropout): Dropout(p=0.1, inplace=False)
  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
hidden_states = tensor([[[ 0.4553, -0.2541,  0.3995,  ..., -0.0000, -0.3704,  0.4796],
         [ 2.2243, -2.3845, -1.7914,  ..., -0.0...2747,  0.4804],
         [-3.1200, -0.5672, -0.0000,  ...,  0.1784,  1.4895, -0.0324]]],
       grad_fn=<MulBackward0>)
distance_matrix = tensor([[[ 5.7445e-01,  5.2147e-01,  1.5548e-01,  6.4518e-01, -1.1406e+00,
          -1.6512e+00, -1.4599e-01,  2.7386...1, -6.6691e-01,  1.2058e+00,  1.5985e+00,
          -1.6347e-01,  1.3332e+00,  1.6939e-01,  7.6006e-02,  5.2039e-01]]])
angle_matrix = tensor([[[-0.6834, -0.8439,  0.8246,  1.2798, -0.3257,  0.0226, -1.8679,
           1.8525,  0.7190,  0.5906],
       ...6108],
         [ 0.0909, -0.5146, -0.4015,  0.1248, -1.2827,  1.4582,  0.3400,
           0.2311, -0.9046, -0.9775]]])
attention_mask = None

    def forward(
        self,
        hidden_states: torch.Tensor,
        distance_matrix: Optional[torch.Tensor] = None,
        angle_matrix: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass with structure awareness
    
        Args:
            hidden_states: Input tensor [batch_size, seq_length, hidden_size]
            distance_matrix: Pairwise distances [batch_size, seq_length, seq_length]
            angle_matrix: Pairwise angles [batch_size, seq_length, seq_length]
            attention_mask: Attention mask [batch_size, seq_length]
    
        Returns:
            output: Transformed hidden states
            attention_probs: Attention probabilities
        """
        # Linear transformations
        query_layer = self.transpose_for_scores(self.query(hidden_states))
        key_layer = self.transpose_for_scores(self.key(hidden_states))
        value_layer = self.transpose_for_scores(self.value(hidden_states))
    
        # Compute base attention scores
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
    
        # Add structure awareness if available
        if distance_matrix is not None:
            distance_embeddings = self.distance_embedding(distance_matrix.unsqueeze(-1))
>           attention_scores = attention_scores + torch.matmul(
                query_layer, distance_embeddings.transpose(-1, -2)
            )
E           RuntimeError: The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 1

models/generative/graph_attention.py:85: RuntimeError
_________ TestStructureAwareGenerator.test_structure_guided_generation _________

self = <tests.generative.test_structure_generator.TestStructureAwareGenerator testMethod=test_structure_guided_generation>

    def test_structure_guided_generation(self):
        """Test generation with structural guidance"""
        start_tokens = torch.randint(0, 22, (self.batch_size, 2))
        max_length = 10
        distance_matrix = torch.randn(
            self.batch_size, max_length, max_length
        )
        angle_matrix = torch.randn(
            self.batch_size, max_length, max_length
        )
    
>       generated = self.generator.generate(
            start_tokens=start_tokens,
            max_length=max_length,
            temperature=0.8,
            distance_matrix=distance_matrix,
            angle_matrix=angle_matrix
        )

tests/generative/test_structure_generator.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/generative/structure_generator.py:157: in generate
    outputs = self.forward(
models/generative/structure_generator.py:106: in forward
    layer_output, attn_weights = attention_layer(
../../.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GraphAttentionLayer(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, ...(output_dropout): Dropout(p=0.1, inplace=False)
  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
hidden_states = tensor([[[-0.7336,  1.9169, -1.6075,  ...,  1.6450, -0.1947,  0.0000],
         [ 1.8787,  0.5411,  0.2550,  ...,  1.7...6835,  0.3195],
         [ 1.3419,  2.4740, -0.5156,  ...,  1.2989, -1.6661,  1.3301]]],
       grad_fn=<MulBackward0>)
distance_matrix = tensor([[[-5.3764e-01,  3.5464e-01,  1.8831e+00, -1.4575e+00, -6.3030e-01,
          -5.9948e-02,  1.3306e+00, -8.1322...1,  3.3655e-01,  2.9710e-01,  4.8404e-01,
          -1.4319e-01, -4.5576e-01,  3.3216e-01, -7.0132e-01, -1.2308e+00]]])
angle_matrix = tensor([[[ 0.0285,  1.5114, -0.2706,  0.8138,  0.4157, -0.1835, -0.9876,
          -2.0641, -1.2857,  0.4450],
       ...2184],
         [-0.4898, -0.7384, -0.5852, -1.8471, -0.4121,  0.4415, -0.6048,
           0.9039, -0.1219, -0.7810]]])
attention_mask = None

    def forward(
        self,
        hidden_states: torch.Tensor,
        distance_matrix: Optional[torch.Tensor] = None,
        angle_matrix: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass with structure awareness
    
        Args:
            hidden_states: Input tensor [batch_size, seq_length, hidden_size]
            distance_matrix: Pairwise distances [batch_size, seq_length, seq_length]
            angle_matrix: Pairwise angles [batch_size, seq_length, seq_length]
            attention_mask: Attention mask [batch_size, seq_length]
    
        Returns:
            output: Transformed hidden states
            attention_probs: Attention probabilities
        """
        # Linear transformations
        query_layer = self.transpose_for_scores(self.query(hidden_states))
        key_layer = self.transpose_for_scores(self.key(hidden_states))
        value_layer = self.transpose_for_scores(self.value(hidden_states))
    
        # Compute base attention scores
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
    
        # Add structure awareness if available
        if distance_matrix is not None:
            distance_embeddings = self.distance_embedding(distance_matrix.unsqueeze(-1))
>           attention_scores = attention_scores + torch.matmul(
                query_layer, distance_embeddings.transpose(-1, -2)
            )
E           RuntimeError: The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 1

models/generative/graph_attention.py:85: RuntimeError
_____________________ test_different_latency_targets[0.1] ______________________

target_latency = 0.1

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac401bffa0>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________________ test_different_latency_targets[0.5] ______________________

target_latency = 0.5

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac40169a50>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
_____________________ test_different_latency_targets[1.0] ______________________

target_latency = 1.0

    @pytest.mark.parametrize("target_latency", [0.1, 0.5, 1.0])
    def test_different_latency_targets(target_latency):
        """Test adaptive processor with different latency targets."""
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>       processor = AdaptiveProcessor(device=device, target_latency=target_latency)

tests/optimizers/test_adaptive_processor.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
models/optimizers/adaptive_processor.py:24: in __init__
    self.hardware_info = self._detect_hardware()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <models.optimizers.adaptive_processor.AdaptiveProcessor object at 0x79ac4054c910>

    def _detect_hardware(self) -> Dict[str, Union[str, int]]:
        """Detect available hardware and capabilities."""
        info = {
            "device_type": "cpu",
            "compute_capability": None,
            "memory_bandwidth": None,
            "cores": psutil.cpu_count(logical=False)
        }
    
        if torch.cuda.is_available():
            info["device_type"] = "cuda"
            device_props = torch.cuda.get_device_properties(self.device)
            info["compute_capability"] = f"{device_props.major}.{device_props.minor}"
>           info["memory_bandwidth"] = device_props.memory_clock_rate * device_props.memory_bus_width / 8
E           AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'memory_clock_rate'

models/optimizers/adaptive_processor.py:52: AttributeError
____________________________ test_log_file_creation ____________________________

performance_monitor = <models.optimizers.performance_monitor.PerformanceMonitor object at 0x79ac40ffdc60>
temp_log_dir = '/tmp/tmpc5k4hq1j'

    def test_log_file_creation(performance_monitor, temp_log_dir):
        """Test log file creation and writing."""
        log_file = Path(temp_log_dir) / "performance.log"
        assert log_file.exists()
    
        # Generate some logs
        performance_monitor._log_metrics("test", {"value": 1.0})
    
        # Check log file content
>       assert log_file.stat().st_size > 0
E       AssertionError: assert 0 > 0
E        +  where 0 = os.stat_result(st_mode=33204, st_ino=5767332, st_dev=66306, st_nlink=1, st_uid=1000, st_gid=1000, st_size=0, st_atime=1734453747, st_mtime=1734453747, st_ctime=1734453747).st_size
E        +    where os.stat_result(st_mode=33204, st_ino=5767332, st_dev=66306, st_nlink=1, st_uid=1000, st_gid=1000, st_size=0, st_atime=1734453747, st_mtime=1734453747, st_ctime=1734453747) = stat()
E        +      where stat = PosixPath('/tmp/tmpc5k4hq1j/performance.log').stat

tests/optimizers/test_performance_monitor.py:204: AssertionError
=============================== warnings summary ===============================
../../.local/lib/python3.10/site-packages/Bio/SubsMat/__init__.py:126
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.
    warnings.warn(

tests/integration/test_performance_benchmarks.py:73
  /home/kasinadhsarma/Pictures/ProtienFlex/tests/integration/test_performance_benchmarks.py:73: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.benchmark

tests/integration/test_protein_validation.py:88
  /home/kasinadhsarma/Pictures/ProtienFlex/tests/integration/test_protein_validation.py:88: PytestUnknownMarkWarning: Unknown pytest.mark.validation - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.validation

tests/analysis/test_multimodal_integration.py::test_sequence_analysis
tests/analysis/test_multimodal_integration.py::test_structure_prediction
tests/analysis/test_multimodal_integration.py::test_function_prediction
tests/analysis/test_multimodal_integration.py::test_multimodal_integration
tests/analysis/test_multimodal_integration.py::test_cross_modal_attention
tests/analysis/test_multimodal_integration.py::test_confidence_estimation
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
    warnings.warn(

tests/generative/test_protein_generator.py::TestProteinGenerator::test_concept_alignment
  /home/kasinadhsarma/Pictures/ProtienFlex/models/generative/protein_generator.py:664: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
    target_tensor = torch.tensor(target_value, device=self.device)

tests/optimizers/test_memory_manager.py::test_checkpoint_sequential
  /home/kasinadhsarma/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
    warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform linux, python 3.10.12-final-0 ----------

=========================== short test summary info ============================
ERROR tests/integration/test_optimization_pipeline.py::test_complete_optimization_pipeline
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_adaptation
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_memory_efficiency
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_performance_tracking
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_error_handling
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[8]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[16]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_batch_sizes[32]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[10]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[20]
ERROR tests/integration/test_optimization_pipeline.py::test_pipeline_different_sequence_lengths[30]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_latency_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_throughput_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_memory_efficiency_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_accuracy_benchmarks
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O1]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O2]
ERROR tests/integration/test_performance_benchmarks.py::TestPerformanceBenchmarks::test_optimization_levels[O3]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_sequence_accuracy
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_structure_prediction
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_fold_recognition
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_binding_site_prediction
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[50]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[100]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_length_scalability[200]
ERROR tests/integration/test_protein_validation.py::TestProteinValidation::test_result_reproducibility
ERROR tests/optimizers/test_adaptive_processor.py::test_adaptive_processor_initialization
ERROR tests/optimizers/test_adaptive_processor.py::test_hardware_detection - ...
ERROR tests/optimizers/test_adaptive_processor.py::test_optimize_for_hardware
ERROR tests/optimizers/test_adaptive_processor.py::test_profile_execution - A...
ERROR tests/optimizers/test_adaptive_processor.py::test_adapt_processing - At...
ERROR tests/optimizers/test_adaptive_processor.py::test_mixed_precision[fp32]
ERROR tests/optimizers/test_adaptive_processor.py::test_mixed_precision[fp16]
ERROR tests/optimizers/test_adaptive_processor.py::test_memory_access_optimization
ERROR tests/optimizers/test_adaptive_processor.py::test_operation_fusion - At...
ERROR tests/optimizers/test_adaptive_processor.py::test_performance_metrics
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[1]
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[2]
ERROR tests/optimizers/test_adaptive_processor.py::test_different_batch_sizes[4]
ERROR tests/optimizers/test_adaptive_processor.py::test_layer_optimization - ...
FAILED tests/generative/test_graph_attention.py::TestGraphAttentionLayer::test_attention_mask
FAILED tests/generative/test_graph_attention.py::TestGraphAttentionLayer::test_structure_aware_attention
FAILED tests/generative/test_protein_generator.py::TestProteinGenerator::test_concept_alignment
FAILED tests/generative/test_protein_generator.py::TestProteinGenerator::test_forward_pass
FAILED tests/generative/test_protein_generator.py::TestProteinGenerator::test_generate_with_concepts
FAILED tests/generative/test_protein_generator.py::TestProteinGenerator::test_structural_validation
FAILED tests/generative/test_protein_generator.py::TestProteinGenerator::test_template_guidance
FAILED tests/generative/test_structure_generator.py::TestStructureAwareGenerator::test_gradient_flow
FAILED tests/generative/test_structure_generator.py::TestStructureAwareGenerator::test_structure_aware_generation
FAILED tests/generative/test_structure_generator.py::TestStructureAwareGenerator::test_structure_guided_generation
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[0.1]
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[0.5]
FAILED tests/optimizers/test_adaptive_processor.py::test_different_latency_targets[1.0]
FAILED tests/optimizers/test_performance_monitor.py::test_log_file_creation
======= 14 failed, 82 passed, 11 warnings, 40 errors in 72.41s (0:01:12) =======
